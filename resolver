#!/usr/bin/python

import re
import argparse
import json
from os.path import basename, splitext

from tree2 import Tree, process_string
from algorithm_cls import resolve_anaphor

gold_data = {}
lexicon = {}
head_settings = {}

def compute_corenlp_accuracy(args):
    convert_all_sentences()


def convert_all_sentences():
    with open("dataset/all_files.txt") as f:
        files = ["dataset/"+splitext(basename(x))[0] for x in f]

    models = ["deterministic", "neural", "statistical"]
    for model in models:
        dict = {}
        counter = 1
        for line in files:
            filename = line+"."+model+".json"
            entry = convert_corenlp_output(filename)
            dict[str(counter)] = entry
            counter += 1

        to_write = {"corefs" : dict}
        
        outfile = "dataset/corenlp_"+model+".json"
        with open(outfile, "w") as f:
            json.dump(to_write, f, indent=2)

def convert_corenlp_output(filename):
    with open(filename) as f:
        output = json.load(f)
    print output["corefs"]

    entry = []
    if len(output["corefs"]) == 0:
        return entry
    else:
        for key in output["corefs"]:
            coref_sets = output["corefs"][key]
            for i in range(len(coref_sets)):
                mention = coref_sets[i]
                dict = {"sentNum" : mention["sentNum"], "text" : mention["text"], "startIndex" : mention["startIndex"], "endIndex" : mention["endIndex"]}
                entry.append(dict)
            
            return entry

def read_gold_data(args):
    with open(args.gold_data) as f:
        gold_data = json.load(f)

    return gold_data


def main(args):
    global lexicon
    with open(args.config_file) as c:
        params = json.load(c)
    lexicon = params[args.language]['lexicon']
    Tree.lexicon = lexicon

    with open(args.sentences) as s:
        parser_output = json.load(s)

    for sentence in sorted(parser_output["sentences"], key=lambda x: x["index"]):
        list_hier = process_string(sentence["parse"])
        tree_to_parse = Tree(list_hier[0], 0)
        print tree_to_parse.get_string()
        tree_to_parse.pretty_print()
        for candidate in filter(lambda x: x.config(), Tree.NP_nodes):
            print "Candidate:", candidate.get_string()
            print "Results:"
            proposed = resolve_anaphor(candidate, Tree.NP_nodes)
            for proposal in proposed:
                print proposal.get_string()
                
        print '-'*20
        Tree.PR_nodes.clear()
        Tree.NP_nodes.clear()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-s",
                        "--sentences",
                        default="binding_dataset.deterministic.json",
                        help="CoreNLP output containing sentences")

    parser.add_argument("-g",
                        "--gold_data",
                        default="gold_data.json",
                        help="Gold data for binding using CoreNLP indexing scheme")

    parser.add_argument("-l",
                       "--language",
                        default="eng",
                        help="Specify 'eng' for English, 'ger' for German")

    parser.add_argument("-c",
                        "--config_file",
                        default="config.json",
                        help="json input for parameter settings. Should not need anything other than the default!")


    parser.add_argument("-o",
                        "--output_file",
                        default="output_tuple.json")

    args = parser.parse_args()
    main(args)
    #compute_corenlp_accuracy(args)
